<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Week1 - HTML Fundamentals</title>
  </head>
  <body>
    <h1>Welcome to Week 1: HTML Fundamentals!</h1>
    <h2>Welcome to Week 1: HTML Fundamentals!</h2>
    <h3>Welcome to Week 1: HTML Fundamentals!</h3>
    <h4>Welcome to Week 1: HTML Fundamentals!</h4>
    <h5>Welcome to Week 1: HTML Fundamentals!</h5>
    <h6>Welcome to Week 1: HTML Fundamentals!</h6>
    <p>Welcome to Week 1: HTML Fundamentals!</p>

    <h1>Beyond Generative: The Rise Of Agentic AI And User-Centric Design</h1>
    <p>
      Developing effective agentic AI requires a new research playbook. When
      systems plan, decide, and act on our behalf, UX moves beyond usability
      testing into the realm of trust, consent, and accountability. Victor Yocco
      outlines the research methods needed to design agentic AI systems
      responsibly.
    </p>

    <h2>A Simple Taxonomy of Agentic Behaviors</h2>
    <p>
      We can categorize agent behavior into four distinct modes of autonomy.
      While these often look like a progression, they function as independent
      operating modes. A user might trust an agent to act autonomously for
      scheduling, but keep it in “suggestion mode” for financial transactions.
    </p>

    <h2>Research Primer: What To Research And How</h2>
    <p>
      Developing effective agentic AI demands a distinct research approach
      compared to traditional software or even generative AI. The autonomous
      nature of AI agents, their ability to make decisions, and their potential
      for proactive action necessitate specialized methodologies for
      understanding user expectations, mapping complex agent behaviors, and
      anticipating potential failures. The following research primer outlines
      key methods to measure and evaluate these unique aspects of agentic AI.
    </p>
    <h3>Mental-Model Interviews</h3>
    <p>
      These interviews uncover users’ preconceived notions about how an AI agent
      should behave. Instead of simply asking what users want, the focus is on
      understanding their internal models of the agent’s capabilities and
      limitations. We should avoid using the word “agent” with participants. It
      carries sci-fi baggage or is a term too easily confused with a human agent
      offering support or services. Instead, frame the discussion around
      “assistants” or “the system.”
    </p>
  </body>
</html>
